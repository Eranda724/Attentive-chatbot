{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7a2340a6-2656-4f28-a600-a53028039fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "Requirement already satisfied: tensorflow-datasets==1.2.0 in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (2.1.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (24.2.0)\n",
      "Requirement already satisfied: dill in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (0.3.9)\n",
      "Requirement already satisfied: future in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (1.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (1.26.4)\n",
      "Requirement already satisfied: promise in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (3.20.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (1.16.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (2.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (4.66.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow-datasets==1.2.0) (1.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tqdm->tensorflow-datasets==1.2.0) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "!pip install tensorflow-datasets==1.2.0\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3e0032bb-b301-4920-a780-0f6721ed383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and extracted.\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    \"cornell_movie_dialogs.zip\",\n",
    "    origin='https://www.kaggle.com/api/v1/datasets/download/soumikrakshit/cornell-movie-dialogs-corpus',\n",
    "    extract=True\n",
    ")\n",
    "path_to_data = os.path.join(os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
    "\n",
    "path_to_movie_lines = os.path.join(path_to_data, \"movie_lines.txt\")\n",
    "path_to_movie_conversations = os.path.join(path_to_data, \"movie_conversations.txt\")\n",
    "\n",
    "print(\"Dataset downloaded and extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0e5ff47e-e09f-4000-ad4b-429c7676791d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\erand\\\\.keras\\\\datasets\\\\cornell movie-dialogs corpus'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b70033b4-95a4-4e07-9e3f-f9891f24b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLE = 50000\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1\", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.,!]+\", \" \", sentence)\n",
    "    return sentence.strip()\n",
    "\n",
    "def load_conversations():\n",
    "    id2line = {}\n",
    "    with open(path_to_movie_lines, errors=\"ignore\") as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.replace(\"\\n\", \"\").split(\" +++$+++ \")\n",
    "        id2line[parts[0]] = parts[4]\n",
    "\n",
    "    inputs, outputs = [], []\n",
    "    with open(path_to_movie_conversations, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.replace(\"\\n\", \"\").split(\" +++$+++ \")\n",
    "        conversation = [line[1:-1] for line in parts[3][1:-1].split(\", \")]\n",
    "        for i in range(len(conversation) - 1):\n",
    "            inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "            outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "            if len(inputs) >= MAX_SAMPLE:\n",
    "                return inputs, outputs\n",
    "    return inputs, outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2c0063f1-176f-4676-9730-47ac9d741301",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = load_conversations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3603f6fc-3016-4115-91b1-751d4030095a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dc3da559-e5f9-41da-8717-4091b422521e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7142b84d-c3b2-4d32-bcb5-7ccd295e56fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : c esc ma tete . this is my head\n",
      "A : right . see ? you re ready for the quiz .\n"
     ]
    }
   ],
   "source": [
    "print(\"Q : {}\".format(questions[10]))\n",
    "print(\"A : {}\".format(answers[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "950bbc2f-d4d5-4f0f-a9e5-9e8008f3c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions+answers,target_vocab_size=2**13\n",
    ")\n",
    "\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size],[tokenizer.vocab_size+1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9949a48d-edf7-4fcb-a0e5-a56367728efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Q : [114, 15, 8, 54, 5, 112, 9, 210, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized Q : {}\".format(tokenizer.encode(questions[30])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0fc94cb1-8bbe-4dca-a357-c9f0a16e3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_filter(inputs,outputs):\n",
    "    MAX_LENGTH = 40  # Example value\n",
    "    tokenized_inputs,tokenized_outputs = [],[]\n",
    "\n",
    "    for (sentence1,sentence2) in zip(inputs,outputs):\n",
    "        sentence1 = START_TOKEN+tokenizer.encode(sentence1)+END_TOKEN\n",
    "        sentence2 = START_TOKEN+tokenizer.encode(sentence2)+END_TOKEN\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <=MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs,maxlen=MAX_LENGTH,padding=\"post\")\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_outputs,maxlen=MAX_LENGTH,padding=\"post\")\n",
    "\n",
    "    return tokenized_inputs,tokenized_outputs\n",
    "\n",
    "questions,answers = tokenize_and_filter(questions,answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6a52f1be-5360-4692-9b0c-6a6c8f376d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44098"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8f64b67e-b561-447c-b130-1f43181eb75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8334"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e4c00bc1-c530-4071-8981-94937d4501c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        \"inputs\": questions,\n",
    "        \"dec_inputs\": answers[:,:-1]\n",
    "    },\n",
    "    {\n",
    "        \"outputs:\": answers[:,1:]\n",
    "    }\n",
    "))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "757227f3-8bc1-45cd-9629-6d87b0d3c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)  # Q * K^T\n",
    "    dk = tf.cast(tf.shape(key)[-1], tf.float32)  # Dimension of key\n",
    "    scaled_attention_logits = matmul_qk / tf.sqrt(dk)  # Scale the attention logits\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  # Apply mask\n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # Softmax along the last axis\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)  # Apply attention weights to the values\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f506d1ea-fb46-4306-a309-cc502cee8974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % self.num_heads == 0\n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs[\"query\"], inputs[\"key\"], inputs[\"value\"], inputs[\"mask\"]\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f9556247-1182-4a53-ba07-e93f21d39835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_layers, hidden_units, dropout_rate):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_units = hidden_units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "        self.encoder_layers = [MultiHeadAttention(d_model, num_heads) for _ in range(num_layers)]\n",
    "        self.decoder_layers = [MultiHeadAttention(d_model, num_heads) for _ in range(num_layers)]\n",
    "        self.dense = tf.keras.layers.Dense(hidden_units, activation='relu')\n",
    "        self.final_layer = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        x = self.embedding(inputs[\"inputs\"])\n",
    "\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer({\"query\": x, \"key\": x, \"value\": x, \"mask\": mask})\n",
    "\n",
    "        decoder_input = self.embedding(inputs[\"dec_inputs\"])\n",
    "\n",
    "        for layer in self.decoder_layers:\n",
    "            decoder_input = layer({\"query\": decoder_input, \"key\": x, \"value\": x, \"mask\": mask})\n",
    "\n",
    "        output = self.dense(decoder_input)\n",
    "        output = self.final_layer(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "aecb31d0-5be3-4b7f-8bdf-8ed2301ab647",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(vocab_size=VOCAB_SIZE, d_model=256, num_heads=8, num_layers=4, hidden_units=1024, dropout_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "90b8883b-e42e-4b23-8ad5-95c9bdf292e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "46bcece1-f9aa-4265-af8a-ca014f7bfef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\erand\\AppData\\Local\\Temp\\__autograph_generated_filersye9ze1.py\", line 24, in tf__call\n        ag__.for_stmt(ag__.ld(self).encoder_layers, None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'layer'})\n    File \"C:\\Users\\erand\\AppData\\Local\\Temp\\__autograph_generated_filersye9ze1.py\", line 22, in loop_body\n        x = ag__.converted_call(ag__.ld(layer), ({'query': ag__.ld(x), 'key': ag__.ld(x), 'value': ag__.ld(x), 'mask': ag__.ld(mask)},), None, fscope)\n    File \"C:\\Users\\erand\\AppData\\Local\\Temp\\__autograph_generated_file06cu0vok.py\", line 19, in tf__call\n        scaled_attention = ag__.converted_call(ag__.ld(tf).transpose, (ag__.ld(scaled_attention),), dict(perm=[0, 2, 1, 3]), fscope)\n\n    ValueError: Exception encountered when calling layer \"transformer_3\" \"                 f\"(type Transformer).\n    \n    in user code:\n    \n        File \"C:\\Users\\erand\\AppData\\Local\\Temp\\ipykernel_15548\\3606762752.py\", line 19, in call  *\n            x = layer({\"query\": x, \"key\": x, \"value\": x, \"mask\": mask})\n        File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\erand\\AppData\\Local\\Temp\\__autograph_generated_file06cu0vok.py\", line 19, in tf__call\n            scaled_attention = ag__.converted_call(ag__.ld(tf).transpose, (ag__.ld(scaled_attention),), dict(perm=[0, 2, 1, 3]), fscope)\n    \n        ValueError: Exception encountered when calling layer \"multi_head_attention\" \"                 f\"(type MultiHeadAttention).\n        \n        in user code:\n        \n            File \"C:\\Users\\erand\\AppData\\Local\\Temp\\ipykernel_15548\\2767108848.py\", line 27, in call  *\n                scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n        \n            ValueError: Dimension must be 5 but is 4 for '{{node transformer_3/multi_head_attention/transpose_3}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32](transformer_3/multi_head_attention/transpose_3/a, transformer_3/multi_head_attention/transpose_3/perm)' with input shapes: [2,?,8,?,32], [4].\n        \n        \n        Call arguments received by layer \"multi_head_attention\" \"                 f\"(type MultiHeadAttention):\n          • inputs={'query': 'tf.Tensor(shape=(None, 40, 256), dtype=float32)', 'key': 'tf.Tensor(shape=(None, 40, 256), dtype=float32)', 'value': 'tf.Tensor(shape=(None, 40, 256), dtype=float32)', 'mask': 'None'}\n    \n    \n    Call arguments received by layer \"transformer_3\" \"                 f\"(type Transformer):\n      • inputs={'inputs': 'tf.Tensor(shape=(None, 40), dtype=int32)', 'dec_inputs': 'tf.Tensor(shape=(None, 39), dtype=int32)'}\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileu2k39blm.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filersye9ze1.py:24\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(layer), ({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m: ag__\u001b[38;5;241m.\u001b[39mld(x), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m: ag__\u001b[38;5;241m.\u001b[39mld(x), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: ag__\u001b[38;5;241m.\u001b[39mld(x), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m: ag__\u001b[38;5;241m.\u001b[39mld(mask)},), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     23\u001b[0m layer \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39membedding, (ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdec_inputs\u001b[39m\u001b[38;5;124m'\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_1\u001b[39m():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filersye9ze1.py:22\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.loop_body\u001b[1;34m(itr)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m x\n\u001b[0;32m     21\u001b[0m layer \u001b[38;5;241m=\u001b[39m itr\n\u001b[1;32m---> 22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkey\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file06cu0vok.py:19\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     17\u001b[0m value \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msplit_heads, (ag__\u001b[38;5;241m.\u001b[39mld(value), ag__\u001b[38;5;241m.\u001b[39mld(batch_size)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     18\u001b[0m scaled_attention \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(scaled_dot_product_attention), (ag__\u001b[38;5;241m.\u001b[39mld(query), ag__\u001b[38;5;241m.\u001b[39mld(key), ag__\u001b[38;5;241m.\u001b[39mld(value), ag__\u001b[38;5;241m.\u001b[39mld(mask)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 19\u001b[0m scaled_attention \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_attention\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mperm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m concat_attention \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreshape, (ag__\u001b[38;5;241m.\u001b[39mld(scaled_attention), (ag__\u001b[38;5;241m.\u001b[39mld(batch_size), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39md_model)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     21\u001b[0m output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdense, (ag__\u001b[38;5;241m.\u001b[39mld(concat_attention),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\erand\\AppData\\Local\\Temp\\__autograph_generated_filersye9ze1.py\", line 24, in tf__call\n        ag__.for_stmt(ag__.ld(self).encoder_layers, None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'layer'})\n    File \"C:\\Users\\erand\\AppData\\Local\\Temp\\__autograph_generated_filersye9ze1.py\", line 22, in loop_body\n        x = ag__.converted_call(ag__.ld(layer), ({'query': ag__.ld(x), 'key': ag__.ld(x), 'value': ag__.ld(x), 'mask': ag__.ld(mask)},), None, fscope)\n    File \"C:\\Users\\erand\\AppData\\Local\\Temp\\__autograph_generated_file06cu0vok.py\", line 19, in tf__call\n        scaled_attention = ag__.converted_call(ag__.ld(tf).transpose, (ag__.ld(scaled_attention),), dict(perm=[0, 2, 1, 3]), fscope)\n\n    ValueError: Exception encountered when calling layer \"transformer_3\" \"                 f\"(type Transformer).\n    \n    in user code:\n    \n        File \"C:\\Users\\erand\\AppData\\Local\\Temp\\ipykernel_15548\\3606762752.py\", line 19, in call  *\n            x = layer({\"query\": x, \"key\": x, \"value\": x, \"mask\": mask})\n        File \"C:\\Users\\erand\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\erand\\AppData\\Local\\Temp\\__autograph_generated_file06cu0vok.py\", line 19, in tf__call\n            scaled_attention = ag__.converted_call(ag__.ld(tf).transpose, (ag__.ld(scaled_attention),), dict(perm=[0, 2, 1, 3]), fscope)\n    \n        ValueError: Exception encountered when calling layer \"multi_head_attention\" \"                 f\"(type MultiHeadAttention).\n        \n        in user code:\n        \n            File \"C:\\Users\\erand\\AppData\\Local\\Temp\\ipykernel_15548\\2767108848.py\", line 27, in call  *\n                scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n        \n            ValueError: Dimension must be 5 but is 4 for '{{node transformer_3/multi_head_attention/transpose_3}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32](transformer_3/multi_head_attention/transpose_3/a, transformer_3/multi_head_attention/transpose_3/perm)' with input shapes: [2,?,8,?,32], [4].\n        \n        \n        Call arguments received by layer \"multi_head_attention\" \"                 f\"(type MultiHeadAttention):\n          • inputs={'query': 'tf.Tensor(shape=(None, 40, 256), dtype=float32)', 'key': 'tf.Tensor(shape=(None, 40, 256), dtype=float32)', 'value': 'tf.Tensor(shape=(None, 40, 256), dtype=float32)', 'mask': 'None'}\n    \n    \n    Call arguments received by layer \"transformer_3\" \"                 f\"(type Transformer):\n      • inputs={'inputs': 'tf.Tensor(shape=(None, 40), dtype=int32)', 'dec_inputs': 'tf.Tensor(shape=(None, 39), dtype=int32)'}\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset , epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d5a85f-300a-4db4-a106-2b5a28ec0f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
